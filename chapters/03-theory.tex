\chapter{Theory}

In this chapter we will cover the theoretical foundations for resource algebras in a CSE settings. We will first cover the current state of the art regarding state models \cref{sec:theory-state-of-affairs}, then what modifications are needed for a CSE to handle RAs \cref{sec:theory-state-model-ras}. This is followed by a list of simple state models \cref{sec:theory-state-models}, that can be used to construct more complex state models via transformers \cref{sec:theory-state-model-transf}. Finally, we look at the theory justifying some optimisations of the \PMap{} state model transformer \cref{sec:theory-optim-pmap}.

\section{State of Affairs} \label{sec:theory-state-of-affairs}

\subsection{State Models with PCMs for CSE}

Abstract separation logic historically has, as discussed previously, mostly used Partially Commutative Monoids (PCMs) \cite{abstractseplogic,sepalgebra,iris1,higherorderseplogic}. These are defined as a tuple ${(M, (\cdot)\colon M\times M\part M, 0)}$, corresponding to the carrier set, composition operator, and a unique identity (or unit) element. These elements must also satisfy the properties highlighted in \autoref{fig:pcm-properties}. PCMs are useful for representing state in Separation Logic, as they ``mathematically represent the essential notions of state ownership and ownership transfer'' \cite{abstractpcm}, while being simple and abstract enough that they can represent a variety of concrete states (the traditional case being that of heaps).

\begin{figure}
	\centering
	\begin{align*}
	\tag{PCM-Assoc} \forall a,b,c&\ldotp (a\cdot b)\cdot c = a\cdot (b\cdot c)\\
	\tag{PCM-Comm} \forall a,b&\ldotp a\cdot b = b\cdot a\\
	\tag{PCM-Identity} \forall a&\ldotp a\cdot 0 = a
	\end{align*} \note{Am I missing something, to highlight the fact it's partial?}
	\caption{Properties of Partially Commutative Monoids}
	\label{fig:pcm-properties}
\end{figure}

When bringing this concept to a Compositional Symbolic Execution (CSE) engine, the PCM must be endowed with a set of actions $\actions$, of core predicates $\preds$, and functions that allow modifying it; in particular, an \execac{} function that reflects program commands that modify the state, a \produce{} function to add an assertion to the state, a \consume{} function to remove an assertion from the state, and a \fix{} function to provide fixes for missing errors in bi-abduction. In \cite{cse1,cse2,sacha-phd}, the notion of state model is thus introduced, to represent a PCM equipped with these attributes. See \autoref{fig:state-model-elements} for a summary of this. 

All of these together enable a CSE engine to be \emph{parametric} on the state model; as long as the provided functions follows a set of axioms, the engine using the state model can be proved to be sound, either in Over-approXimate (OX) or Under-approXimate (UX) mode, in turn allowing for program verification, or true bug finding.

\emph{Core predicates} (sometimes simply called predicates) are used to make the assertion language of the engine parametric. They take inspiration from \cite{abstractseplogic}, and are written $\delta\in\preds$. To enable this parametricity, the assertions of the language are extended with a core predicate assertion, written $\corepred{\delta}{\ins}{\outs}$, where $\delta$ is the core predicate, $\ins$ are the \emph{in-values} (or ``ins'') of the predicate, and $\outs$ are the \emph{out-values} (or ``outs''). This distinction is used for automation purposes, to create matching plans: they tell the engine that given the values $\ins$, the state can return the corresponding $\outs$ associated with it. For instance, the traditional ``points to'' assertion $a \mapsto v$, where $a$ is an address and $v$ a value, can be written as $\corepred{\pointsto}{a}{v}$: given the address $a$, a heap can return the value store at the location $v$. Core predicate also thus imply a satisfiability relation, denoted $\st\modelsp\corepred{\delta}{\ins}{\outs}$ to signify a state satisfies a given predicate. Predicate satisfiability happens at the concrete level, and is later lifted to the symbolic realm by evaluating the ins and outs using a substitution $\theta$ and variable store $s$; expression evaluation is denoted $\expeval{\sym e}=e$. Another traditional example is the \emp{} core predicate, that is satisfied by the empty memory; it can be written $\corepred{\code{emp}}{}{\!}$.

\begin{remark}[Semantics of emp]
There are two accepted and clashing semantics of the \emp{} assertion; either it is equivalent to $\vtrue$ and any state satisfies \emp{}, or it represents strictly the empty memory and nothing else -- the former is more appropriate for garbage collected languages while the latter for \alloc/\free{} languages. \cite{sljungle}

Here we make the arbitrary choice of defining it as only being satisfied by the empty memory. Because the engine is parametric on the core predicates, a user is free to chose the semantics appropriate to their use case -- this is a strength of the parametric approach.
\end{remark}

\emph{Actions} are used to represent program actions that interact with the state. Typical actions include \load{}, \store{}, \alloc{} or \free. These actions are called with a list of arguments, return a list of results, and may modify the state, as long as the modification are sound with regards to a set of axioms, presented later.

\begin{figure}\centering
\setlength{\fboxsep}{0.3cm}
\noindent\fbox{\parbox{\textwidth-3cm}{
\textbf{Elements:} \begin{compactitem}
\item $(\St, (\cdot)\colon\St\times \St\part \St, 0)$: PCM of concrete states.
\item $\Sst$: Set of symbolic states.
\item $\actions$: Set of actions.
\item $\preds$: Set of core predicates.
\end{compactitem} \vspace{0.3cm}
\textbf{Functions:} \begin{compactitem}
\item \execac: execute an action with arguments, returns a value.
\item \produce: add a core predicate assertion into the state, returns the new state.
\item \consume: removes a core predicate assertion from the state, returns the new state and the outs of the assertion.
\item \fix: returns the assertions needed to fix the given missing error.
\end{compactitem}\vspace{0.3cm}
\textbf{Theoretical Properties:} \note{Is `properties' the right word?}
\begin{compactitem}
\item $\models$: symbolic interpretation relation.
\item $\modelsp$: core predicate satisfiability relation.
\end{compactitem}
}}%
\vspace{0.2cm}
\caption{High-level description of the elements of a state model}
\label{fig:state-model-elements}
\end{figure}

We may now look at an example of function, to understand how the state model is used. In code, we denote a program variable \code{x} by it's name, a symbolic variable $\sym x$ by \code{\#x}, a core predicate \corepred{\delta}{\ins}{\outs} as \code{<$\delta$>($\ins$;$\outs$)}, and commands that use an action $\alpha$ as \code{[$\alpha$](args)}. The pre and postcondition are written before the function's declaration, enclosed in double square brackets \code{[[...]]}. Now looking at the function \code{set\_value} in \autoref{fig:example-spec}, which has the following specification:
\begin{align*}%
\ESLtriple%
	{\code{a}=\sym a \star \code{x} = \sym x \star \corepred{\pointsto}{\sym a}{\sym v}}%
	{\code{set\_value(a, x)}}%
	{\code{ret} = \sym a \star \corepred{\pointsto}{\sym a}{\sym x}}
\end{align*}%
If the engine aims to verify the function, it will start with an empty state and \emph{produce} all assertions of the pre-condition (the order being determined by the matching plan). Here, this means adding the assertions $\code{a} = \sym a$ and $\code{x} = \sym x$ to the path condition, and producing the core predicate \corepred{\pointsto}{\sym a}{\sym v} into the state. It will then execute the action \code{store} on the state model, with arguments $[\sym a, \sym x]$ (note the program variables are substituted with the symbolic variable associated). In the linear heap, this simply modifies the value stored at $\sym a$, setting it to $\sym x$. The code then returns \code{a}, thus assigning its value, $\sym a$, to the special variable \code{ret} which represents the value returned by the function. Finally, to ensure the state at the end of the function matches the postcondition, the assertions are consumed; first asserting $\code{ret} = \sym a$ holds, and then consuming \corepred{\pointsto}{\sym a}{\sym x}, effectively removing the binding from the state. All the above executes succesfully, and the function is thus verified.

\begin{figure}\centering
\begin{lstlisting}
[[ a == #a * x == #x * <points_to>(#a; #v) ]]
[[ ret == #a * <points_to>(#a; #x) ]]
proc set_value(a, x) {
	[store](a, x);
	return a;
}
\end{lstlisting}
\caption{Simple function to set a value}
\label{fig:example-spec}
\end{figure}

The same also applies with more complex functions. For the case of function calls using function specifications, the inverse is done: when calling a function its precondition is consumed, and its postcondition is produced, effectively \emph{framing off} the corresponding state, and then framing back on the post condition.

\subsection{Where it goes wrong}

While PCMs are an obvious and straightforward choice for representing state ownership, they come with certain drawbacks. Firstly, PCMs can be overly restrictive; in particular, the presence of a unit $0$ is restrictive, in that it makes constructions of sums impossible: for that, one needs to allow for multiple units in the object. In \cite{sepalgebra}, it is shown that where a PCM fulfills $\exists u\ldotp \forall x\ldotp x\cdot u = x$, one can allow for more units by simply swapping the existentials: $\forall x\ldotp \exists u\ldotp x \cdot u = x$. This rule is further relaxed in \cite{iris}, where it is shown that not having a unit at all can also be useful, in particular when one wants to construct these \emph{Resource Algebras} (RAs) from simpler elements. Finaly, and as noted in \cite{iris}, they are not enough for certain applications, such as when wanting to support higher-order logic.

In \cite{sacha-phd}, the concept of RA constructions from \cite{iris} is brought into a CSE setting, using PCMs. The original work however contained some errors in constructions, that created unsoundness in the verification tool. These errors stemmed, from the most part, to the use of PCMs, and again the existence of the unit $0$. Indeed, this made some constructions, such as sum, freeable or the partial map unsound. We will now look at examples of these.

\subsubsection{Unsoundness in Freeable}

The first example is with $\Freeable_\PCM(\mmdl)$. This state model \emph{transformer} is given a state model $\mmdl$, and extends it with the capacity to free state, via the \free{} action. It also adds a \freedP{} predicate, to represent freed memory.

Now consider the simple state model $\Freeable_\PCM(\Ex_\PCM(\nats))$. Here $\Ex_\PCM(X)$ is the exclusive state model, that represents exclusive ownership of a value of type $X$\footnote{Note we write $\Ex_\PCM(X)$ and $\Freeable_\PCM(\mmdl)$ -- the $\Ex_\PCM$ state model accepts a set, $X$, whereas $\Freeable_\PCM$ accepts a state model, $\mmdl$.}. Ownership is indicated via the $\exP$ core predicate: \corepred{\exP}{}{x} means the state currently has the value $x$ -- this state model will be further defined later, and is only used here for the example. For now, we define the PCM version of $\Ex_\PCM(X)$ as:
\begin{align*}
	\Ex_\PCM(X) &\defeq \ex{x\colon X} ~|~ 0
\end{align*}

The notation $\ex{x\colon X}$ is equivalent to $\{ \ex{x} : \forall x\in X \}$. We thus define $\Ex_\PCM(X)$ as the set of elements of $X$ \emph{and} the $0$ element. We also define composition such that $0\cdot \st=\st\cdot 0=\st$ and $\ex{x} \cdot \ex{y}$ is always undefined: since the value is owned exclusively, we can't own two values simultaneously. This satisfies the axioms of PCMs. We now consider a naive definition of $\Freeable_\PCM(\mmdl)$'s PCM, where $\St$ is the carrier set of $\mmdl$'s PCM:
\begin{align*}
	\Freeable_\PCM(\mmdl) &\defeq \text{sub}(\st\colon \St) ~|~ \freed ~|~ 0
\end{align*}

We then again define composition as $0 \cdot \st=\st \cdot 0=\st$, and $\text{sub}(\st) \cdot \text{sub}(\st')=\text{sub}(\st\cdot \st')$. This again forms a valid PCM. $\Freeable_\PCM$ exposes a core predicate \freedP, as well as the core predicates of the underlying memory model. While we omit the full details of the state model, we note that producing \freedP{} only succeeds when in state $0$ (since a state can't be both freed and something else), producing something other that \freedP{} calls the \produce{} function of the underlying state model $\mmdl$, and stores the resulting state $\st$ as $\text{sub}(\st)$. Similarly, consuming a predicate of $\mmdl$ while in state $\text{sub}(\st)$ calls \consume{} on that predicate with $\st$, and then wraps the result $\st'$ back into $\text{sub}(\st')$.

Now consider the \code{dispose} function, as seen in \autoref{fig:example-dispose-freeable}. Given an owned memory value storing $1$, it simply frees it\footnote{For these examples we only use concrete values, to make them simpler and omit substitutions that happen with symbolic values -- the same results would also hold when using symbolic values, of course.}. This function is called by \code{call\_dispose}, which does just that. It follows that these two functions should be verified, as it is fairly obvious that they fullfil their specifications.

\begin{figure}\centering
\begin{lstlisting}
[[ <ex>(; 1) ]]
[[ ret == 0 * <freed>(;) ]]
proc dispose() {
	[free]();
	return 0;
}

[[ <ex>(; 1) ]]
[[ ret == 0 * <freed>(;) ]]
proc call_dispose() {
	dispose();
	return 0;
}
\end{lstlisting}
\caption{Simple function to set a value}
\label{fig:example-dispose-freeable}
\end{figure}

Let's now, step by step, inspect the verification of \code{call\_dispose}. First, we set up the initial state, producing \corepred{\exP}{}{1} onto the empty state $0$ -- our state is now, according to the above definitions, $\text{sub}(\ex{1})$. We now execute the function's body, calling the \code{dispose} function. To do this, we first need to consume its precondition: we consume \corepred{\exP}{}{1} from the state $\text{sub}(\ex{1})$. To do this, $\Freeable_\PCM$ calls the \consume{} function of $\Ex_\PCM(\nats)$, with the state $\ex{1}$, which returns $0$. $\Freeable_\PCM$ then wraps this state back, resulting in $\text{sub}(0)$. We then produce the post-condition of \code{dispose}, thus producing \corepred{\freedP}{}{} into $\text{sub}(0)$. This however is not valid, according to the rules outlined earlier! Indeed the state can't both be freed and something else. Of course, $\text{sub}(0)$ represents an empty state, but that means that the \consume{} and \produce{} rules of $\Freeable_\PCM$ must take this into account -- a simple implementation could miss it, resulting in such errors.

This difficulty in fact turns out from the existence of both $0$ and $\text{sub}(0)$ as two distinct states, despite them being the same semantically: empty. To fix this, one must either make $\text{sub}(0)$ invalid, defining it as $\text{sub}(x\colon \St \setminus \{0\})$, or instead remove the definition of $0$ and instead use $\text{sub}(0)$ as the unit of $\Freeable_\PCM$. Either cases require one to be quite careful around the unit, as forgetting about it may lead to unwanted errors.

\subsubsection{Unsoundness in Sum}\label{sec:unsoundness-in-sum}

The sum state model $\Sum(\mmdl_1, \mmdl_2)$, also written $\mmdl_1 + \mmdl_2$, represents a state where either one of the two sides is owned, but not both. It is a useful as it allows representing states with transitions -- for instance, $\Freeable(\mmdl)$, introduced before, can also be defined as $\mmdl + \Ex(\{\freed\})$.

While this state is useful in that it allows modelling transitions from one side of the sum to another, it is in fact non-trivial to define in a way that is both OX-sound and UX-sound. In particular, neither sides of the sum must permit the $0$ element, if a state $\st$ allows swapping no other smaller state $\st'\preo\st$ must allow swapping, and the state swapped into must be \emph{exclusively owned}. This property is taken from \cite{iris}, and for PCMs can be defined as: \begin{align*}
	\isexowned_\PCM~\st \defeq \forall \st'\ldotp \st'\neq 0\implies \neg(\st\disj\st')
\end{align*}

The proof that the above properties must hold can be found in \cref{ap:sum-soundness}. Again we note how the presence of a $0$ adds requirements around these constructions, cluttering otherwise elegant definitions.

\subsubsection{Unsoundness in PMap}

Finally, we consider how PCMs can cause unsoundness in the partial map state model transformer $\PMap(I, \mmdl)$. It allows mappings from a domain $I$ to a codomain state from $\mmdl$. Again it will be fully defined in \cref{sec:theory-state-model-transf}. For this example we consider the state model construction $\PMap_\PCM(\nats, \Ex_\PCM(\nats))$, and we define the PCM of $\PMap_\PCM$ as: \begin{align*}
	\PMap_\PCM(I, \mmdl) &\defeq (I \finmap \St) \times \pset(I)^?
\end{align*}

We omit the precise details of how exactly it works. $\PMap_\PCM(I,\mmdl)$ \emph{lifts} all predicates of $\mmdl$ with an additional in-value corresponding to the location $i\in I$ to which the predicate corresponds. All action executions receive an additional argument with the location, and similarly all \consume{} and \produce{} calls must have the index in their ins. The behaviour of a naive implementation would then be similar to what was explained for $\Freeable_\PCM$: calling \consume{} or \produce{} when the binding is not present executes it against the $0$ element of the underlying PCM, and otherwise calls it on the state at the location and stores the result back at that location, overriding the previous binding. The right hand side of the product, $\pset(I)^?$, represents the domain set of the partial map, in other words the set of addresses that are known to exist -- any address outside of the set does not exist. The~$-^?$ signifies that we extend $\pset(I)$ with the element $\bot$, in which case the domain set is not known. The core predicate $\corepred{\domainset}{}{d}$ is satisfied by the state with the domain set $d$. The \produce{} function of $\PMap_\PCM$ also ensures that a well-formedness constraint is upheld; in particular, given a state $(h,d)$ with $h$ the heap and $d$ the domainset, if $d\neq\bot$, then $\dom(h)\subseteq d$.

Now, consider the following function specification, that moves a value:
\begin{align*}
\ESLtriple{\corepred{\exP}{1}{1} \star \corepred{\domainset}{}{\{1\}}}{\code{move()}}{\corepred{\exP}{2}{1} \star \corepred{\domainset}{}{\{2\}}}
\end{align*}
Let the initial state be $(\{ 1\mapsto \ex{1}\}, \{ 1\} )$: a heap with one cell, at address $1$ -- this matches the precondition of \code{move}. The engine first consumes the \exP{} predicate from $\ex{1}$, at address $1$ -- this means the pointed-to state becomes $0$, and the outer state becomes $(\{ 1\mapsto 0\}, \{ 1\})$. The \domainset{} predicate is then successfully consumed too, leaving $(\{ 1\mapsto 0\},\bot)$. Now, the post-condition is produced onto the state. First, the engine produces \corepred{\exP}{2}{1}, which adds a binding to $\PMap_\PCM$ and creates the cell: our bigger state is now $(\{ 1\mapsto 0, 2\mapsto \ex1\},\bot)$. Finally, \corepred{\domainset}{}{\{2\}} is produced onto the state, however this \emph{doesn't succeed}. Indeed, we have $\dom(\{1\mapsto 0, 2\mapsto \ex1\})=\{1,2\}$, and of course $\{1,2\}\not\subseteq \{2\}$: the domain of the heap is not a subset of the produced domain set $\{2\}$. This is caused because again we forgot to check if the state at location $1$ became $0$ when consuming $\ex1$. We would thus need to check for this, and potentially redefine the PCM of $\PMap_\PCM$ to forbid mappings to $0$.

These examples hopefully showed that PCMs enforce a unit that is unwieldy, and can easily cause to unsound behaviour when forgotten. Even when taken into account, it leads to unpleasant definitions, as every state model must define a $0$, and every state model transformer must then either exclude it in its construction, or explicitly take it into account.

\subsection{RAs for Iris}

Iris \cite{iris1,iris2,iris3,iris} departs from this tradition of PCMs, and introduces Resource Algebras (RAs) to model state, defined as a tuple ${(M, \irisval\colon M\rarr \text{iProp}, |-|\colon M\rarr M^?, (\cdot)\colon M\times M\rarr M)}$, containing the carrier set, a validity function, a partial core function and a \emph{total} composition operator. This definition makes use of the option RA $M^?\defeq M\uplus\{\bot\}$ \cite{iris-option}, that extends the set of $M$ with an ``empty'' element $\bot$, such that $m\cdot\bot=\bot\cdot m=\bot$. Similarly to PCMs, a set of axioms must be satisfied, as seen in \autoref{fig:irisra-properties}.

\begin{figure}
\centering
\begin{align}
	\tag{Iris-RA-Assoc} \forall a,b,c&\ldotp (a\cdot b)\cdot c = a\cdot (b\cdot c)\\
	\tag{Iris-RA-Comm} \forall a,b&\ldotp a\cdot b = b\cdot a\\
	\tag{Iris-RA-Core-ID} \forall a&\ldotp |a| \in M \Rarr |a|\cdot a = a\\
	\tag{Iris-RA-Core-Idem} \forall a&\ldotp |a|\in M\Rarr ||a|| = |a|\\
	\tag{Iris-RA-Core-Mono} \forall a,b&\ldotp |a|\in M\land a\preo b \Rarr |b| \in M \land |a| \preo |b|\\
	\tag{Iris-RA-Valid-Op} \forall a,b&\ldotp \irisval(a\cdot b)\Rarr \irisval(a)
\end{align}
\begin{align*}
	\text{where}\qquad
	M^? &\defeq M \uplus \{\bot\}\text{, with }a\cdot \bot \defeq \bot\cdot a\defeq a\\
	a \preo b &\defeq \exists c\ldotp b = a\cdot c\\
	a \rightsquigarrow B &\defeq \forall c^? \in M^?\ldotp \irisval(a\cdot c^?) \Rarr \exists b\in B\ldotp \irisval(b\cdot c^?)\\
	a \rightsquigarrow b &\defeq a \rightsquigarrow \{b\}
\end{align*}
A \emph{unital} resource algebra is an RA $M$ with an element $\epsilon\in M$ such that:
\begin{align*}
	\irisval(\epsilon) &&
	\forall a\in M. \epsilon\cdot a = a&&
	|\epsilon|=\epsilon
\end{align*}
\caption{Definition of resource algebras in Iris}
\label{fig:irisra-properties}
\end{figure}

The \emph{core function} $|-|\colon M\rarr M^?$ associates to an element $m$ of the RA it's \emph{duplicable core}. The crucial difference here, compared to PCMs, is that aside from allowing multiple units, it allows having \emph{no unit}, in which case $|m|=\bot$. As we will see later, having no unit is a requirement for a state to be exclusively owned (i.e. it has no frame). Indeed, if the state $m$ has a core $|m|\neq\bot$, then that core always constitutes a valid frame.

The \emph{validity function} $\irisval\colon M\rarr \text{iProp}$ is used to rule out invalid compositions, rather than relying on the partiality of the composition operator. It returns an Iris property, \text{iProp}, which allows for step indexing and some more sophisticated logic, that it out of the scope of this project. As such, most RAs are extended with an invalid element $\lightning$, and validity is often defined as $\irisval(m)\defeq m\neq \lightning$. For instance for the $\Ex_\Iris$ RA: \begin{align*}
	\Ex_\Iris(X) &\defeq \ex{x\colon X} ~|~ \lightning \\
	\irisval(a) &\defeq a \neq \lightning \\
	|\ex{a}| &\defeq \bot\\
	a \cdot b &\defeq \lightning
\end{align*}

The validity and core functions thus make Iris states more powerful, in that they have more flexibility in what can be expressed; while a regular PCM can be trivially converted to an RA, the opposite is not true. An example of construction that can easily be more easily constructed is the sum state model. The requirement for a transition from one side of the sum to the other can be more elegantly expressed, without having to worry about the existence of $0$s \cite{iris}. Given ${\text{exclusive}(a)\defeq \forall b\ldotp \neg\irisval(a\cdot b)}$, we have:\begin{mathpar}
\inferrule[ExclusiveUpdate]{\text{exclusive(a)} \\ \irisval(b)}{a \rightsquigarrow b}
\end{mathpar}

The Iris udpate $a \rightsquigarrow b$ is a form of frame preserving update: if we update $a$ into $b$, we know that any frame that was compatible with $a$ remains compatible with $b$.

Furthermore, Iris is a battle-tested logic\footnote{See \url{https://iris-project.org/\#publications}, where more than a hundred publications are cited as using Iris, allowing for the verification of, among others, C, Go, OCaml, Rust, Scala or WASM.}, that comes with plenty of proofs and properties making them easy to use and adapt, whereas PCMs can prove unwieldy even for simpler state models as shown previously.

We note an interesting similarity between Iris and the PCM approach however, which is that ``the global RA must be unital, which means it should have a unit element $\epsilon$'' \cite{iris}. This is similar to what one would find in a PCM, where we have the $0$ element. Any RA can be trivially extended to have a unit, via the option RA. This in particular means that while the building blocks of both approaches are differents (PCMs or RAs), the end result that is used is similar. This is good news: it means that adapting an RA construction to a CSE engine that uses PCMs should be fairly straightforward, as one can rely on the unit $\epsilon$ as a de facto $0$.

\section{State Models with RAs} \label{sec:theory-state-model-ras}

We have seen how PCMs are unpractical for a CSE engine, as they easily create incorrect behaviour that can be quite tricky to notice. We will now see how we may adapt a CSE to instead use RAs. We first define the notion of partial RAs, followed by the description of the changes done to the engine's layers to support partial RAs. Finally, we list the new axioms that must be respected by the functions of the state model.

\subsection{Partial RAs}

A property of Iris RAs is that composition is \emph{total} -- to take into account invalid composition, states are usually extended with a $\lightning$ state, such that $\neg \irisval(\lightning)$ (while for states $\st\neq\lightning$, $\irisval(\st)$ holds). While this is needed in the Iris framework for higher-order ghost state and step-indexing, this doesn't come into play when one is only manipulating RAs. As such, because having to define and later verify the validity of states can be quite unwieldy, we remove it by instead making use of partiality, as was originally the case in PCMs. This translation is done by removing the invalid state $\lightning$ when present, and instead defining compositions that lead to it as undefined. From this, we can get rid of the validity function, and define composition as being partial: $(\cdot)\colon M\times M\part M$. This is also in line with the core function $(-)$ being partial.

\begin{figure}
A \emph{resource algebra} (RA) is a triple $(M, |\!-\!|\colon M\rarr M^?, (\cdot)\colon M\times M \part M)$

\begin{align}
	\tag{RA-Assoc} \forall a,b,c&\ldotp (a\cdot b)\cdot c = a\cdot (b\cdot c)\\
	\tag{RA-Comm} \forall a,b&\ldotp a\cdot b = b\cdot a\\
	\tag{RA-Core-ID} \forall a&\ldotp |a| \in M \Rarr |a|\cdot a = a\\
	\tag{RA-Core-Idem} \forall a&\ldotp |a|\in M\Rarr ||a|| = |a|\\
	\tag{RA-Core-Mono} \forall a,b&\ldotp |a|\in M\land a\preo b \Rarr |b| \in M \land |a| \preo |b|
\end{align}
\begin{align*}
	\text{where}\qquad
	M^? &\defeq M \uplus \{\bot\}\text{, with }a\cdot \bot \defeq \bot\cdot a\defeq a\\
	a \preo b &\defeq \exists c\ldotp b = a\cdot c\\
	a\disj b &\defeq a \cdot b \text{ is defined}
\end{align*}
A \emph{unital} resource algebra is a resource algebra $M$ with an element $\epsilon\in M$ such that:
\begin{align*}
	\forall a\in M\ldotp \epsilon\cdot a = a&&
	|\epsilon|=\epsilon
\end{align*}
\caption{Definition of (partial) resource algebras}
\label{fig:ra-properties}
\end{figure}

\begin{remark}[Partiality and the option RA]
	One may note that we use the term ``partial'' to refer to two different signatures; the core $|-|\colon M \rarr M^?$ is called partial but is in fact total, with undefined mappings being equal to $\bot$, while the composition $(\cdot)\colon M\times M\part M$ is an actual partial function.
	
	While one could adapt the core to be $M\part M$, this would prove unpractical, in cases when one still wants to use $|m|$ even when it is $\bot$. On the other hand, defining composition as $M\times M\rarr M^?$ is simply incorrect: let $a\cdot b$ undefined, it is untrue that $(a\cdot b)\cdot c=c$, while defining an undefined composition to equal $\bot$ would render this statement true.
\end{remark}

\emph{Partial} RAs are equivalent to regular RAs, as long as ${\neg\irisval(a)\Rarr \neg\irisval(a\cdot b)}$ holds -- luckily for us, this is equivalent to the axiom \textsc{Iris-RA-Valid-Op}. Compositions that yield $\lightning$ (or any state $m$ such that $\neg\irisval(m)$) can be made undefined, and the validity function removed, to gain partiality, and inversely to go back to the Iris definition.

An interesting property of this change is that because validity is replaced by the fact composition is defined, the validity of a composition $\irisval(a\cdot b)$ in a RA is exactly equivalent to the fact two elements are disjoint in a partial RA $a \disj b$, when we define disjointness as composition being defined.

We now define the properties of partial RAs taking this change into account -- see \autoref{fig:ra-properties}. From now, the term RA will be used to refer to these partial RAs.

We may compare the definition of $\Ex_\Iris$, presented earlier, with the equivalent definition using partial RAs, $\Ex$. The main difference is the removal of $\irisval$ and the $\lightning$ element, making the definition simpler.

\noindent\begin{minipage}{.5\linewidth}
\begin{align*}
	\Ex_\Iris(X) &\defeq \ex{x\colon X} ~|~ \lightning \\
	\irisval(a) &\defeq a \neq \lightning \\
	|\ex{a}| &\defeq \bot\\
	a \cdot b &\defeq \lightning
\end{align*}\end{minipage}%
\begin{minipage}{.5\linewidth}
\begin{align*}
	\Ex(X) &\defeq \ex{x\colon X} \\
	|\ex{a}| &\defeq \bot\\
	a \cdot b & \text{ is always undefined}
\end{align*}\end{minipage}


\subsection{Core Engine}

We're now interested into what changes need to be brought to our CSE to handle RAs. To do this, we use the axioms and definitions specified in \cite{cse2}. We will also specify additional changes that exist in Gillian and that were formalised in \cite{sacha-phd}, but that haven't been added to the formalisation described in \cite{cse2}.

This CSE engine is split into three layers, each adding functionality to the layer below, allowing for a lear separation of concerns. These layers are, from bottom to top: the core engine, the compositional engine, and the bi-abduction engine (see \autoref{fig:layers-cse-engine}).

\begin{figure}
	\centering
	\includegraphics[width=12cm]{diagrams/engine-layers.drawio.pdf}
	\caption{Layers of the CSE engine}
	\label{fig:layers-cse-engine}
\end{figure}

The core engine enables whole-program symbolic execution. For this, state models must firstly define the set of states the execution will happen on. While \emph{concrete} compositional state is modelled as an RA, \emph{symbolic} compositional state is simply a set of elements that does not come with composition or cores. This is because when one handles symbolic values, composition isn't a partial function anymore, as it can branch, and thus output more than one value. Take for instance the RA of trees, where nodes are defined as having an offset and size. Composing two trees made of a single node with a symbolic offset may lead to different results, depending on the interpretation of the offsets: are the two nodes adjacent? Which is on the left or the right? This cannot be modelled with an RA. Soundness of the engine is instead verified by unlifting symbolic states to concrete states via symbolic interpretation $\models$, and then using the properties of these concretes states, which do form a valid RA. 

Once the set of symbolic states $\Sst\ni\sst$ are defined, they must be further equipped with a set of actions $\actions$ and an $\execac$ function that allow the program to modify the state. We also include the definition of the $\models$ relation, called \code{sat}, noting that this is a purely theoretical construct that isn't implemented in the actual engine.
\begin{align*}
	\execac &\colon \St^? \rarr \actions \rarr \vallist \rarr \outcomes_e \times \St^? \times \vallist\\
	\execac &\colon \Sst^? \rarr \actions \rarr \lvallist \rarr \pset(\outcomes_e \times \Sst^? \times \lvallist \times \Pc) \\
	\code{sat} &\colon \Theta \rarr \text{Store} \rarr \Sst \rarr \pset(\St)
\end{align*}

We define two different versions of \execac{}: one operating on concrete states, that is deterministic, and one operating on symbolic states, that allows branching. The concrete version of the function is used in the theory, to prove the soundness of its symbolic counterpart, while the symbolic version is what is actually used by the engine to execute the analysed program.

In the concrete case, the arguments of \execac{} are, in order: the \emph{optional} state the action is executed on, the action, and the received arguments. It returns an outcome, the new state and the returned values. It is pretty-printed as \ppexecc{\alpha}{\st,\ins}{o, \st', \outs}.

For its symbolic counterpart, the arguments are lifted to the symbolic realm. It also returns a set of branches, along with a path condition $\pc$ (PC) representing the condition for the branch to exist -- if the PC is not satisfiable, the branch must be cut. It is pretty-printed as \ppexec{\alpha}{\sst,\sins}{o, \sst', \souts, \pc}.

Here, the outcome is in the set of \emph{execution outcomes} $\outcomes_e=\{ \Ok,\Err,\Miss \}$. Where $\Ok$ represents succesful execution and $\Err$ program errors, $\Miss$ outcomes come from the compositional nature of the state. An action that leads to a $\Miss$ doesn't necessarily represent a bug in the code, but simply that additional state is needed to determine whether execution is succesful or not. In the next subsection, this set will be extended to account for logical failures, which exist outside the semantics of the language.

The main difference with \cite{cse2} is that the state may be $\bot$, if the action is executed on empty state; this is made explicit from using $\Sst^?$ (rather than $\Sst$). This ensures non-unital RAs are not ruled out as invalid -- indeed, many useful RAs are not unital and sometimes don't have a unit at all, as is the case for instance for \Ex, the exclusively owned value. 

We also modify the definition of a path condition. It is typically defined as a logical value $\LVal$ that must evaluate to a boolean, and which is extended via conjunction. Internally, the engine however still needs to split the conjunction into a list of terms to manipulate it. As such, to make the theory closer to what is effectively done within the engine, we make the choice of defining the path condition as a \emph{list of logical values}: $\pc\in\Pc=\lvallist$. Extension is then defined as concatening new logical values to the path condition, and strenghtening of the path condition can be trivially checked by checking $\pc'\supseteq\pc$. We further define the predicate \code{SAT}, that is true if, given the substitution $\theta$, store $s$ and a path condition $\pc$, the conjunction of the elements of $\pc$ resolves to $\vtrue$ once evaluated:
\begin{align*}
	\SAT(\pc) \defeq \left\llbracket \bigwedge_{i}^{|\pc|}\pc(i) \right\rrbracket_{\theta,s} \hspace{-1em} = \vtrue
\end{align*}

The original definition of the symbolic \execac{} presented in \cite{cse2} also has an ``\SV'' argument, a set containing all existing symbolic variables. This set is used when an action creates a fresh symbolic variable, to ensure the variable is fresh. While necessary for proofs within the engine in Rocq, we omit it here, as it is only relevant for one action (\alloc), and pen and paper proofs do not require the same rigidity as a Rocq proof. 

Finally, the user must define the \code{sat} relation, relating concrete and symbolic states. It is pretty printed as $\theta,s,\st\models \sst$ for $\st\in\code{sat}~\theta~s~\sst$, meaning that given a substitution $\theta$ and a store $s$, the concrete state $\st$ can be matched by a symbolic state $\sst$. The user must only define this relation for non-$\bot$ states; we can then lift it to the option state model $\St^?$, by simply adding that $\forall \theta, s\ldotp \theta,s,\bot \models \bot$. This relieves users from needing to take $\bot$ into account when defining $\models$ and from proving the axiom \ref{eq:empty-mem}.

\subsection{Compositional Engine}

The compositional engine, built on top of the core engine, allows for verification of function specifications, and handles calling functions by their specification. As such, the state model must be extended with a set of core predicates $\preds$ and a pair of \consume{} and \produce{} functions (equivalent, respectively, to a resource assert and assume). Finally, to link core predicates to states, a core predicate satisfiability relation $\modelsp$ (called $\code{sat}_\preds$) must be defined in the theory, to prove soundness of \consume{} and \produce.
\begin{align*}
	\text{for }M=\{\OX, \UX\}\\
	\consume &\colon M\rarr \Sst^? \rarr \Delta \rarr \lvallist \rarr \pset(\outcomes_l \times \Sst^? \times \lvallist \times \Pc) \\
	\produce &\colon \Sst^? \rarr \Delta \rarr \lvallist \rarr \lvallist \rarr \pset(\Sst^? \times \Pc)\\
	\code{sat}_\Delta &\colon\St^? \rarr \Delta \rarr \vallist \rarr \pset(\vallist)
\end{align*}
Similarly to \execac, the input state can be $\bot$. While intuitively one may assume that the input state of \consume{} and the output state of \produce{} may never be $\bot$ (as there must be a non-empty state to consume an assertion from or produce an assertion into), this would limit what core predicates can do. In particular, this means an $\emp$ predicate couldn't be defined, since it's production on an empty state results in an empty state.

The arguments of \consume{} are, in order: the mode of execution, to distinguish between under-approximate and over-approximate reasoning, the state, the core predicate being consumed, the ins of the predicate. It outputs a \emph{logical outcome}, the state with the matching predicate removed (which may result in an empty state $\bot$), the outs of the predicate and the associated path condition. It is pretty-printed as \ppcons{m,\sst,\delta,\sins}{o, \sst_f, \souts, \pc}, and when the consumption is valid for both \OX{} and \UX{} the mode is omitted.

For \produce{}, the arguments are the state, the core predicate being produced, the ins and the outs of the predicate, resulting in a set of new states and their associated path condition. As an example, producing $\sym x \mapsto 0$ in a state $[1 \mapsto 2]$ results in a new state $[1\mapsto 2, \sym x \mapsto 0]$ with the path condition $[\sym x \neq 1]$. If the produced predicate is incompatible with the state (e.g. producing $1 \mapsto y$ in a state containing $1 \mapsto x$), the producer \emph{vanishes}. Inversely, if the assertion can be interpreted in several ways, the producer may branch. It is pretty-printed as $\ppprod{\sst,\delta,\sins,\souts}{\sst', \pc}$.

The $\code{sat}_\preds$ relation relates a possibly empty \emph{concrete} state, core predicate and in-values to a set of out-values. It is pretty-printed as $\st \modelsp \corepred{\delta}{\ins}{\outs}$ for $\outs \in \code{sat}_\preds~\st~\delta~\ins$. For instance in the linear heap state model, we have $[ 1 \mapsto 2 ] \modelsp \corepred{\pointsto}{1}{2}$. This definition is similar to the definition of predicates in \cite{abstractseplogic,localreasoning}, where a predicate is defined exactly as a set of states. We lift $\code{sat}_\preds$ to the symbolic realm: 
\begin{align*}
	\theta,s,\st\modelsp \corepred{\delta}{\sins}{\souts} \defeq \expeval{\sins}=\ins \land \expeval{\souts}=\outs \land \st\modelsp \corepred{\delta}{\ins}{\outs}
\end{align*}

Here we define logical outcomes $\outcomes_l = \{\Ok, \LFail, \Miss \}$. These are outcomes that happen during reasoning; in particular, \LFail{} equates to a logical failure due to an \emph{incompatibility} between the consumed predicate and the state. For instance, consuming $1 \mapsto 1$ from a state $[1 \mapsto 2]$ would yield a \LFail{}, while consuming it from state $[2 \mapsto 1]$ would yield a \Miss{}, as the state $[1\mapsto 1]$ could be composed with it to yield a non-miss outcome. 

An addition to what \cite{cse2} previously defined, taking inspiration from \cite{sacha-phd}, is thus the split of what was the \code{Abort} outcome into \LFail{} and \Miss{}, which improves the quality of error messages and allows \emph{fixing} consumptions that yield a \Miss{} -- this will be described in the next subsection. 

\begin{figure}
	\centering
	\includegraphics[width=5cm]{diagrams/outcomes-overlap.drawio.pdf}
	\caption{Overlap of outcomes}
	\label{fig:outcomes-overlap}
\end{figure}

We thus have $\outcomes_e$ for execution outcomes, and $\outcomes_l$ for reasoning outcomes -- one is returned by action execution, and one for predicate consumption (see \autoref{fig:outcomes-overlap}). They overlap on one particular feature of the engine, which is function calls by specification: when calling a function, any outcome can happen: $\Ok$ if the function call succeeds, $\Err$ if the function call faults (as defined by its specification), $\Miss$ if additional resources are needed to satisfy the precondition of the function specification, and $\LFail$ if the state is incompatible with the function specification.

A last change done to what \cite{cse2} defines is that the path condition parameter of  \consume{} and \produce{} is removed, disallowing both functions from inspecting the path condition -- the functions instead directly return the path condition required for the resulting branches. This brings several advantages: firstly, it simplifies the axioms for \consume{} and \produce{}, as there is no need to require that they strengthen the PC. Instead, the returned PC is always concatenated with the current PC, ensuring it can only be strengthened. Secondly, it simplifies the definition of \consume{}, as whether the branch is cut or not (to satisfy \OX{} and \UX{} soundness) is also delegated to the engine. For instance, in UX all consumption branches that result in \LFail{} can be dropped, as dropping branches is UX-sound -- in OX however, this is not sound. A typical pattern in \consume{} implementations is thus to evaluate the modified PC, and if an \LFail{} is reached drop the branch depending on the mode. By omitting the PC from the arguments, this responsability is thus delegated to the engine. Finally, this makes a particular optimisation of the engine simpler to implement: incremental SMT solving\footnote{Z3, which is used in Gillian, uses ``scopes'' for this -- see \url{https://microsoft.github.io/z3guide/docs/logic/basiccommands/\#using-scopes}}. This is a mechanism that allows storing an intermediary state in the SMT solver (a ``checkpoint''), adding to the state, and later backtracking to the checkpointed state to evaluate another branch if needed. By ensuring \consume{} and \produce{} only returns what to append to the PC, the checkpoint can easily be added before the call, and then each branch's PC added and evaluated. Allowing \consume{} and \produce{} to modify the PC directly would mean the PC must be parsed and filtered, to tell apart old from new terms -- modified terms would make this even harder.

\subsection{Bi-Abduction Engine}

To support bi-abduction in the style of Infer:Pulse \cite{pulse}, \Miss{} outcomes must be fixed. This enables true UX bug finding in under-specified or unspecified functions. For this, the state model must provide a \fix{} function, that given the details of a miss error (these details being of type \lvallist{} and returned with the outcome) returns a \emph{list of sets of assertions} that must be produced to fix the missing error. 
\begin{align*}
	\fix \colon \lvallist \rarr \pset(\text{Asrt}) ~\code{list}
\end{align*}
A \emph{list} of different fixes is returned, which themselves are a set of assertions -- this is because, for a given missing error, multiple fixes may be possible which causes branching. For instance, trying to load a cell that is not found in the state can lead to two possible fixes: either the cell is present, and the fix is $\{ \corepred{\pointsto}{\sym a}{\sym x} \}$, either the cell is not present anymore because it has been freed (which would then lead to a use after free error), giving the fix $\{{\corepred{\code{freed}}{\sym a}{}}\}$.

\subsection{Axioms}

We may now go over the axioms that must be respected by the above defined functions for the soundness of the engine. Note we only mention the axioms related specifically to the state models -- axioms relating to the overall soundness of the engine or the core semantics are out of the scope of this report.

For all of the axioms we assume we have a symbolic state model $\mmdl$, made of the concrete states RA $\St \ni \st$, symbolic states set $\Sst \ni \st$, actions $\actions$ and core predicates $\preds$.

We split the axioms into two parts: those relating to the symbolic nature of state and ensuring soundness with regards to a concrete state, and those relating to the parametricity of the state.

\subsubsection{Symbolicness Axioms}

\begin{equation}
\tag{Empty Memory}\label{eq:empty-mem}
\theta,s,\st\models \bot \iff \st = \bot
\end{equation}

The above axiom is obtained for free, by lifting the $\models$ relation to the option RA.

\begin{equation}
\tag{Memory Model OX Soundness}\label{eq:mem-ox-soundness}
\begin{array}{l}
\theta,s,\st\models\sst \land \ppexecc{\alpha}{\st,\ins}{o,\st',\outs} \land \expeval{\sins}=\ins ~\land \\
(\forall o', \sst', \souts', \pc'\ldotp \ppexec{\alpha}{\sst,\sins}{o',\sst',\souts',\pc'} \Rarr o' \in \{ \Ok, \Err \}) \implies \exists \sst',\souts,\pc,\theta'\ldotp\\
\quad \ppexec{\alpha}{\sst,\sins}{o,\sst',\souts,\pc} \land \theta',s,\st'\models \sst' \land  \SAT[\theta',s](\pc) \land \expeval[\theta',s]{\souts}=\outs
\end{array}
\end{equation}

\begin{equation}
\tag{Memory Model UX Soundness}\label{eq:mem-ux-soundness}
\begin{array}{l}
\ppexec{\alpha}{\sst,\sins}{o,\sst',\souts,\pc} \land \SAT[\theta',s](\pc) \land \theta,s,\st'\models\sst' \land \\
\expeval[\sym s,\pc]{\souts}\rightsquigarrow(\outs,\pc')\land \expeval[\sym s,\pc']{\sins}\rightsquigarrow(\ins,\pc'')\implies\\
\quad \exists \st\ldotp \theta,s,\st\models\sst \land \ppexecc{\alpha}{\st,\ins}{o,\st',\outs}
\end{array}
\end{equation}

The above two axioms are at the core of OX and UX soundness, respectively. The former ensure that if a concrete execution exists, then it must also exist in the symbolic semantics; it however doesn't ensure that more executions that those that actually exist may happen. The latter ensures that if a symbolic execution exists, then it must also exist in the concrete world; this time, no guarantees are made regarding the existence of such symbolic transition: for instance, symbolic semantics that never result in any branches are UX-sound (though they are of limited use).

Because incorrectness separation logic does execution backwards (ensuring all states satisfying a postcondition $Q$ are reachable from a precondition $P$), we also prove UX soundness of the memory model backwards: if the resulting state has a concrete model, then so must the state before. In OX, soundness is instead forwards: if the starting state is sound, so must be the resulting state.

\subsubsection{Compositionality Axioms}

\begin{equation}
\tag{Frame subtraction}\label{eq:frame-sub}
\begin{array}{l}
\st\disj\st_f \land \ppexecc{\alpha}{\st\cdot\st_f,\sins}{o, \st',\outs} \implies \\
\quad\exists \st'', o', \outs'\ldotp \ppexecc{\alpha}{\st,\ins}{o', \st'', \outs'} ~\land \\
\qquad(o' \neq \Miss \implies o' = o \land  \outs' = \outs \land \st' = \st'' \cdot \st_f)
\end{array}
\end{equation}

\begin{equation}
\tag{Frame Addition}\label{eq:frame-add}
\begin{array}{l}
\ppexecc{\alpha}{\st,\ins}{o, \st', \outs} \land o \neq \Miss \land \st'\disj\st_f\implies\\
\quad\st \disj \st_f \land \ppexecc{\alpha}{\st\cdot\st_f, \ins}{o, \st'\cdot\st_f, \outs}
\end{array}
\end{equation}

The above two axioms are what enable the traditional frame rule of separation logic, but bringing it to operational semantics. Frame substraction in particular is almost identicaly to the ``Frame property'' defined in \cite{localreasoning}: if executing an action on a state from which a frame was removed yields a non-\Miss, then that action did not need that frame, and the frame can be added to the result. For frame addiction, which is needed in UX, we go backwards again: if a frame can be added to the state after executing an action and the action doesn't cause a \Miss, then it can also be added to the state before without interfering with the action execution.

\begin{equation}
\tag{Consume OX Soundness}\label{eq:consume-ox-sound}
\begin{array}{l}
\ppcons{\sst,\delta,\sins}{\Ok,\sst_f,\souts,\pc} \implies \forall \theta,s,\st_f,\st_\delta\ldotp \\
\quad \theta,s,\st_f\models \sst_f \land \theta, s, \st_\delta \modelsp \corepred{\delta}{\sins}{\souts} \land \st_f\disj\st_\delta \implies \\
\qquad \exists \st\ldotp \st = \st_\delta \cdot \st_f \land \theta,s,\st\models \sst \land \SAT(\pc)
\end{array}
\end{equation}

\begin{equation}
\tag{Consume OX: No Path Drops}\label{eq:consume-ox-no-drop}
\begin{array}{l}
(\forall o, \sst_f,\souts,\pc \ldotp \ppcons{\OX,\sst,\delta,\sins}{o, \sst_f, \souts, \pc}\Rarr o_c = \Ok) \implies \\
\quad \exists  \sst_f',\souts',\pc' \ldotp \ppcons{\OX, \sst, \delta,\ins,\pc}{\Ok, \sst_f', \souts', \pc'}
\end{array}
\end{equation}

\begin{equation}
\tag{Consume UX Soundness}\label{eq:consume-ux-sound}
\begin{array}{l}
\ppcons{\sst,\delta,\sins}{\Ok,\sst_f,\souts,\pc} \implies \forall \theta,s,\st\ldotp \\
\quad  \theta,s,\st\models \sst \land \SAT(\pc) \implies \exists \st_\delta, \st_f\ldotp\\
\qquad \st_\delta\disj\st_f \land \st=\st_\delta\cdot\st_f \land \theta, s, \st_\delta \modelsp \corepred{\delta}{\sins}{\souts} \land \theta,s,\st_f\models \sst_f
\end{array}
\end{equation}

The above three axioms show the soundness of \consume{} for OX and UX operations. They are similar to \ref{eq:mem-ox-soundness} and \ref{eq:mem-ux-soundness} respectively. We also have an additional requirement for OX execution, stating that if there is no erroneous execution of \consume{} then at least one succesful execution exists. 

\begin{equation}
\tag{Produce: OX Soundness}\label{eq:produce-ox-sound}
\begin{array}{l}
\theta, s, \st_f \models \sst_f \land \theta, s, \st_\delta \modelsp \corepred{\delta}{\sins}{\outs} \land \st_f\disj\st_\delta \implies \\
\quad \exists \sst\ldotp \ppprod{\sst_f,\delta,\sins,\souts}{\sst,\pc} \land \SAT(\pc) \land \theta,s,(\st_f\cdot\st_\delta) \models \sst
\end{array}
\end{equation}

\begin{equation}
\tag{Produce: UX Soundness}\label{eq:produce-ux-sound}
\begin{array}{l}
\ppprod{\sst_f,\delta,\sins,\souts}{\sst, \pc} \implies\\
\quad \forall\theta,s,\st\ldotp \SAT(\pc) \land \theta,s,\st\models\sst \implies \exists \st_\delta, \st_f\ldotp \\
\qquad \st_\delta\disj\st_f \land \st=\st_\delta\cdot\st_f \land \theta,s,\st_\delta \modelsp \corepred{\delta}{\sins}{\souts} \land \theta,s,\st_f \models \sst_f
\end{array}
\end{equation}

Again, these two axioms show soundness of \produce{} for OX and UX operation. For the former, we show that if two disjoint states exist in the concrete world and one of the two satisfies a core predicate, then producing that predicate onto the other yields their composition. For the latter, we state that if \produce{} yields a branch that is satisfiable then there must exist a model of the result.

There are no axioms that \fix{} needs to satisfy -- as it simply results in assertions, it cannot break soundness. Either it produces no fixes or only incompatible fixes and we vanish, which is UX sound, or it finds fixes that work, in which case we already know the execution exists in the concrete world and we remain UX sound.

\section{State Models} \label{sec:theory-state-models}

Now that the CSE engine is defined and the properties of state models are axiomatised, we focus on primitive state model, that can be later used to build up complex state. We first look at the base case, \Ex{}, followed by the state model of knowledge or agreement, \Ag. Finally, we look at an in-between, \Frac, that allows exclusive ownership with a form of sharing.

\subsection{Exclusive}

The exclusive state model $\Ex(X)$ presented earlier is the simplest form of state model. It asserts ownership of an element of the set $X$, provide one core predicate $\exP$, and two actions to modify the state, $\load$ and $\store$. The $\exP$ predicate has no ins, and one out: the value stored.
\begin{align*}
 	\Ex(X) &\defeq	\ex{x\colon X}\\
 	|\ex{x}| &\defeq \bot\\
 	\ex{x_1} \cdot \ex{x_2}&~\text{is always undefined}
\end{align*}

\begin{figure}
	\centering
	\begin{mathpar}
\inferrule[ExStoreOk]{}{\ppexec{\store}{\ex{\sym x}, [\sym x']}{\Ok, \ex{\sym x'}, [], []}}
\and\inferrule[ExStoreMiss]{}{\ppexec{\store}{\bot,[\sym x']}{\Miss,\bot,[],[]}}
\and\inferrule[ExConsOk]{}{\ppcons{\ex{\sym x}, \exP, []}{\Ok, \bot, [\sym x], []}}
\and\inferrule[ExProd]{}{\ppprod{\bot,\exP, [], [\sym x]}{\ex{\sym x}, []}}
\and\inferrule[ExFix]{}{\fix ~[] = [\{ \exists \sym x\ldotp \corepred{\exP}{}{\sym x} \}]}
	\end{mathpar}
	\caption{Some rules for \Ex}
	\label{fig:ex-rules-example}
\end{figure}

The first notation, $\Ex(X)$ is the state model instantiation from the set $X$ to the $\Ex$ resource algebra. The notation $\ex{x\colon X}$ stands for $\{\ex{x} : \forall x\in X \}$ -- here `$\ex{x}$' refers to the particular element of the $\Ex(X)$ RA where the value is $x\in X$.

See \autoref{fig:ex-rules-example} for an extract of the rules for \Ex{} -- the full definition can be found in \autoref{rules:ex}. We also show side by side the rules for the concrete and symbolic actions in \autoref{fig:ex-rules-con-vs-sym}: in particular we note that they are strikingly similar, the latter simply being lifted from the former.

\begin{figure}
	\centering
	\begin{mathpar}
\inferrule[CExStoreOk]{}{\ppexecc{\store}{\ex{x}, [x']}{\Ok, \ex{x'}, []}}
\and\inferrule[ExStoreOk]{}{\ppexec{\store}{\ex{\sym x}, [\sym x']}{\Ok, \ex{\sym x'}, [], []}}
\and\inferrule[CExStoreMiss]{}{\ppexecc{\store}{\bot,[x']}{\Miss,\bot,[]}}
\and\inferrule[ExStoreMiss]{}{\ppexec{\store}{\bot,[\sym x']}{\Miss,\bot,[],[]}}
	\end{mathpar}
	\caption{Side by side comparison of concrete and symbolic action rules for \Ex{} -- concrete rules are prefixed with \textsc{C}.}
	\label{fig:ex-rules-con-vs-sym}
\end{figure}

The only difference for \Ex{} between RAs and PCMs is the absence of a $0$, which is instead $\bot$; in fact $\Ex(X)^?$ is strictly equivalent to $\Ex_\PCM(X)$.

To provide at least one full of example of state model, we also include the definition of the symbolic interpretation and core predicate satisfiability relations -- both are trivial, simply checking for equality:
\begin{mathpar}
\inferrule[ExSymInterpretation]{\expeval{\sym x}=x}{\theta,s,\ex{x}\models\ex{\sym x}}
\and\inferrule[ExPredSat]{\st=\ex{x}}{\st\modelsp\corepred{\exP}{[]}{[x]}}
\end{mathpar}

\subsection{Agreement}

The agreement state model $\Ag(X)$ is the counterpart to the exclusively owned state model -- it allows sharing, and is duplicable. It defines one predicate, $\agP$, and a single action, $\load$. Again, $\agP$ has no ins and one out, the value. Mutating state is not sound with a duplicable resource, as that doesn't satisfy \ref{eq:frame-add} or \ref{eq:frame-add}: a frame that is compatible with the original value is not compatible with the modified value, as they are not equal anymore.
\begin{align*}
	\Ag(X) &\defeq \ag{x\colon X}\\
	|\ag{x}| &\defeq \ag{x}\\
	\ag{x} \cdot \ag{x'} &\defeq \begin{cases}
 	\ag{x} &\If~x = x' \\
 	\text{undefined} &\Otherwise
 \end{cases}
\end{align*}

\begin{figure}
	\centering
	\begin{mathpar}
\inferrule[AgLoadOk]{}{\ppexec{\load}{\ag{\sym x},[]}{\Ok,\ag{\sym x},[\sym x],[]}}
\and\inferrule[AgConsOk]{}{\ppcons{\ag{\sym x},\agP,[]}{\Ok,\ag{\sym x},[\sym x],[]}}
\and\inferrule[AgProdBot]{}{\ppprod{\bot,\agP,[],[\sym x]}{\ag{\sym x}, []}}
\and\inferrule[AgProdEq]{}{\ppprod{\ag{\sym x},\agP,[],[\sym x']}{\ag{\sym x}, [\sym x = \sym x']}}
	\end{mathpar}
	\caption{Some rules for \Ag}
	\label{fig:ag-rules-example}
\end{figure}

See \autoref{fig:ag-rules-example} for an extract of its rules. Its duplicative nature can be seen in the rules \textsc{AgConsOk} and \textsc{AgProdEq}: consuming the predicate doesn't turn it into $\bot$ but leaves it untouched, while producing into an already present state suceeds as long as the predicate's out and the state are equal, as seen in the path condition: $[\sym x = \sym x']$.

An observation that can be made from this is that for consumption to be sound, the resulting state can never be \emph{anything less than the input's core}. \note{Otherwise function call by specification is not frame preserving, I think? (At least with \Ag.) But this isn't defined as an axiom or anything, so I'm not sure what to do with it. It doesn't follow from any axiom, and I haven't proved it for any state model (though I'm sure it holds). Is it OK to just leave it here as it is still an insight, without building upon it?} \begin{align*}
	\ppcons{\sst,\sins}{\Ok,\sst',\souts,\pc} \land \theta,s,\st\models\sst \land \theta,s,\st'\models\sst' \implies |\st| \preo \st'
\end{align*}

Unline \Ex, \Ag{} is \emph{not cancellative}: in other words, $a\cdot b = a\cdot c \nRightarrow b=c$, since for instance $\ag{x} \cdot \bot=\ag{x}\cdot\ag{x}$, but $\bot\neq\ag{x}$. Cancellativity is a property that was initially thought to be required for separation algebras \cite{abstractseplogic,sepalgebra}, but that has since been dropped \cite{statesoundness,iris}.

The agreement state model is thus useful to model immutable, shareable state -- for instance, it is used in the JavaScript instantiation (discussed in a later section) to represent the address of an object's metadata, as this information is immutable. This was first brought to a CSE engine in JaVerT \cite{javert1,javert2}, though when that was developed the notion of an ``agreement state model'' didn't exist and as such it wasn't identified as one.

\subsection{Fraction}

The fractional state model $\Frac(X)$ allows for exclusive ownership while allowing sharing, via fractional permissions. This was first introduced in \cite{fracpermissions,fracpermissions2}, where the ``points to'' assertion was equipped with a fraction $q$: a state satisfying $a\mapstoq{1}x$ has full ownership (read and write) of $x$, and can be split into $a\mapstoq{q}x \star a\mapstoq{1-q}x$, creating two states with read-only permissions. The \Frac{} memory model is a generalisation of this at the value level. It defines one predicate, $\fracP$, that has one in, the fraction $q$, and one out, the value $x$. Just like $\Ex$, it provides a \load{} and a \store{} action -- the only difference being that a fraction of $1$ is required to modify the value. Because the max fraction is $1$, we know that when it is $1$ no frame can have ownership of the value, and it can thus safely be modified.
\begin{align*}
	\Frac(X)&\defeq \fracc{x\colon X, q\colon (0;1]}\\
	|\fracc{x, q}| &\defeq \bot\\
	\fracc{x,q}\cdot\fracc{x',q'}&\defeq \begin{cases}
		\fracc{x,q+q'} & \If~ x=x' \land q+q' \leq 1\\
		\text{undefined} &\Otherwise
	\end{cases}
\end{align*}

We put the fraction $q$ in the in values of the $\fracP$ core-predicate to allow \consume{} to subtract exactly the permission required from the state -- if both the permission and the value were out-values, then \consume{} would always evaluate to $\bot$, cancelling the main advantage of this state model. The rules for \consume{} can be seen in \autoref{fig:frac-consume-rules}. We note here that in the symbolic state model, the fraction part is also lifted to the symbolic realm, allowing for a symbolic permission.

\begin{figure}
	\centering
	\begin{mathpar}
\inferrule[FracConsAll]{}{\ppcons{\fracc{\sym x,\sym q},\fracP,[\sym q']}{\Ok,\bot,[\sym x],[\sym q=\sym q']}}
\and\inferrule[FracConsSome]{}{\ppcons{\fracc{\sym x,\sym q},\fracP,[\sym q']}{\Ok,\fracc{\sym x,\sym q-\sym q'},[\sym x],[0 < \sym q' < \sym q]}}
\and\inferrule[FracConsMiss]{}{\ppcons{\fracc{\sym x,\sym q},\fracP,[\sym q']}{\Miss,\fracc{\sym x,\sym q},[\sym q' - \sym q],[\sym q < \sym q' \leq 1]}}
\and\inferrule[FracConsFail]{}{\ppcons{\fracc{\sym x,\sym q},\fracP,[\sym q']}{\LFail,\fracc{\sym x,\sym q},[],[\sym q' \leq 0 \lor 1 < \sym q']}}
	\end{mathpar}
	\caption{\consume{} rules for \Frac}
	\label{fig:frac-consume-rules}
\end{figure}

Because the outcome of actions depends on the amount of permission owned, \Frac{} is also a good example to show how one may adapt a concrete state model into a symbolic state model, by moving the relevant concrete conditions into the path condition. The rules for the concrete and symbolic \store{} are shown in \autoref{fig:frac-store-rules}. Note how, between \textsc{CFracStorePerm} and \textsc{FracStorePerm}, the condition $q < 1$ is replaced by $\sym q < 1$, and is returned in the path condition, rather than being checked for in the rule itself, since the value of $\sym q$ depends on the current PC.

\begin{figure}
	\centering
	\begin{mathpar}
\inferrule[CFracStoreOk]{q=1}{\ppexecc{\store}{\fracc{x,q},[x']}{\Ok,\fracc{x',q},[]}}
\and\inferrule[FracStoreOk]{}{\ppexec{\store}{\fracc{\sym x,\sym q},[\sym x']}{\Ok,\fracc{\sym x',\sym q},[],[\sym q=1]}}
\and\inferrule[CFracStorePerm]{q<1}{\ppexecc{\store}{\fracc{x,q},[x']}{\Miss,\fracc{x,q},[1-q]}}
\and\inferrule[FracStorePerm]{}{\ppexec{\store}{\fracc{\sym x,\sym q},[\sym x']}{\Miss,\fracc{\sym x,\sym q},[1-\sym q],[\sym q<1]}}
	\end{mathpar}
	\caption{\store{} rules for \Frac}
	\label{fig:frac-store-rules}
\end{figure}

While this state model is conceived taking into account fractional permissions, other separation algebras exist to tackle the same problem. For instance, \cite{fracpermissions} also proposes a counting permissions system: $a\mapstoq{0}x$ is a writing permission, and it can issue reading permissions denoted $a\part x$, such that $a\mapstoq{q}x \iff a\mapstoq{q+1}x \star a\part x$. Though we do not define it in full, this could also be implemented as a state model, providing two core predicates: \corepred{\code{write}}{q}{x} and \corepred{\code{read}}{}{x}, with every consumption of \code{read} from a writeable state increasing $q$, and inversely every production of \code{read} decreasing it, and checking $q=0$ when using \store. This shows state modes seem to be the right abstraction, as they support a variety of resource algebras.

\section{State Model Transformers} \label{sec:theory-state-model-transf}

While the above state models can prove useful, they are limited in use, only allowing the storage of one value. One would likely want to model state that is more complex than this, storing a range of values in a variety of ways. Iris introduces the idea of RA constructions \cite{iris} -- this idea has then been adapted to Gillian in \cite{sacha-phd}, with PCMs. Here we re-visit these constructions, porting them to RAs.

\subsection{Sum}

The sum state model $\Sum(\mmdl_1,\mmdl_2)$, also written $\mmdl_1 + \mmdl_2$, allows representing states that can be in either the states of $\mmdl_1$ or $\mmdl_2$. This state model doesn't introduce any core predicates or actions, and instead simply lifts those of the two underlying state models. Let $\actions_1$ and $\preds_1$ the actions and core predicates of $\mmdl_1$, and $\actions_2$ and $\preds_2$ those of $\mmdl_2$, the actions of the sum are defined as ${\actions = \{\code{L}\alpha : \alpha \in \actions_1 \} \uplus \{\code{R}\alpha : \alpha \in \actions_2 \}}$, and the core predicates as ${\preds = \{\code{L}\delta : \delta \in \preds_1 \} \uplus \{\code{R}\delta : \delta \in \preds_2 \}}$. Actions and predicates are simply tagged with what side of the sum they originate from.

Let $\St_1$ and $\St_2$ be the carrier sets of the RAs of $\mmdl_1$ and $\mmdl_2$ respectively; the RA of $\Sum(\mmdl_1,\mmdl_2)$ is:
\begin{align*}
	\Sum(\mmdl_1, \mmdl_2) \defeq \mmdl_1+\mmdl_2 &\defeq l(\st\colon \St_1) ~|~ r(\st\colon \St_2)\\
	l(\st)\cdot l(\st') &\defeq l(\st\cdot \st')\\
	r(\st)\cdot r(\st') &\defeq r(\st\cdot \st')\\
	|l(\st)|&\defeq \begin{cases}
 		\bot &\If~ |\st|=\bot\\
 		l(|\st|) &\Otherwise
	 \end{cases}\\
	 |r(\st)|&\defeq \begin{cases}
 		\bot &\If~ |\st|=\bot\\
 		r(|\st|) &\Otherwise
	 \end{cases}
\end{align*}

In \cref{sec:unsoundness-in-sum} we showed how $\Sum_\PCM$ must disallow the unit on each side to be sound. In RAs however, this is not an issue anymore, as the underlying state models can simply not define a unit. We may also redefine \isexowned, to take into account that the unit is not present in the carrier set, giving a much simpler definition: \begin{align*}
	\isexowned~\st \defeq \nexists \st'\in\St\ldotp \st\disj\st'
\end{align*}

The rules of the \Sum{} state model are otherwise straightforward, lifting \execac, \consume{} and \produce{} to the sum from the underlying state models. The only minor difference is when a \Miss{} occurs -- because fixes are only generated from a $\lvallist$, \Sum{} has no way of knowing which side raised the \Miss, and can thus not call the \fix{} function of the correct side. To avoid this, when the outcome of \execac{} or \consume{} is a \Miss{} we concatenate an identifier to the values to allow discriminating between the two. An extract of these rules is shown in \autoref{fig:sum-miss-example}.

\begin{figure}
	\centering
\begin{align*}
	\text{Given }
	\mathit{wrap}_l(x) = \begin{cases}
		\bot &\If~x=\bot\\
	 	l(x)&\Otherwise
	 \end{cases} \text{ and }
	 \mathit{unwrap}_l(x_l) = \begin{cases}
 		\bot &\If ~x=\bot\\
 		x &\If~x_l=l(x)\\
 		\text{undefined}&\Otherwise
	 \end{cases}
\end{align*}
	\begin{mathpar}
\inferrule[SumLAction]{\sst=\mathit{unwrap}_l(\sst_l) \\ \ppexec{\alpha}{\sst,\sins}{o,\sst',\souts,\pc} \\ \sst_l' = \mathit{wrap}_l(\sst') \\ o \neq \Miss}{\ppexec{\code{L}\alpha}{\sst_l,\sins}{o,\sst_l',\souts,\pc}}
\and\inferrule[SumLActionMiss]{\sst=\mathit{unwrap}_l(\sst_l) \\ \ppexec{\alpha}{\sst,\sins}{\Miss,\sst',\souts,\pc} \\ \sst_l' = \mathit{wrap}_l(\sst')}{\ppexec{\code{L}\alpha}{\sst_l,\sins}{\Miss,\sst_l',\strv{l}::\souts,\pc}}
\and\inferrule[SumLFix]{\mmdl_1.\fix~\sins=a}{\fix~\strv{l}::\sins=a}
	\end{mathpar}
	\caption{Rules for handling \Miss{} in \Sum}
	\label{fig:sum-miss-example}
\end{figure}

This example is interesting in that it also the constraint imposed by the fact $\bot\notin\Sst$: it is often needed to define auxiliary $\fn{unwrap}$ and $\fn{wrap}$ functions, that get the state out a value if it is not $\bot$, and returns $\bot$ otherwise. In other words, $\fn{unwrap}\colon\Sst_1^?\part\Sst_2^?$ and $\fn{wrap}\colon\Sst_2^?\rarr\Sst_1^?$. While these are straightforward to define and use, they can clutter rules a bit, in favour of not needing to handle $\bot$ and non-$\bot$ cases separately.

\subsection{Product}

The product state model $\Product(\mmdl_1, \mmdl_2)$, also written $\mmdl_1 \times \mmdl_2$, allows representing pairs of states, where each side belongs to a specific state model. For instance, one could chose to represent the $\Frac(X)$ state model as $\Ex(X) \times \Frac_{\mathbb{Q}}$, where $\Frac_{\mathbb{Q}}$ is an exclusively owned rational in the $(0;1]$ where composition is addition. This is, in fact, the way Iris defines $\Frac$ \cite{iris-thesis} -- however, this approach makes using the state model less practical, as one would need to define a separate predicate for each side.

Iris also defines the product RA, by simply lifting pointwise the operations on each side of the product. We call this initial definition $\Product_0$, defining it as: \begin{align*}
 	\Product_0(\mmdl_1,\mmdl_2)&\defeq \St_1 \times \St_2\\
 	(\st_l,\st_r)\cdot(\st_l',\st_r') &\defeq (\st_l\cdot \st_l',\st_r\cdot \st_r')\\
 	|(\st_l,\st_r)|&\defeq \begin{cases}
(|\st_l|, |\st_r|) &\If~|\st_l|\neq\bot \land |\st_r|\neq\bot\\
\bot&\Otherwise
\end{cases}
\end{align*}

This definition, while straightforward, has a problem: indeed, while its sets of states is $\St_1\times\St_2$, we still have that $\bot\notin\St$. If an empty ($\bot$) states produces a core predicate for one of its sides, what happens to the other side? Indeed, while one side becomes defined, such that $\st_l\in\St_1$, $(\st_l, \bot)$ is not a valid state, since $\bot \notin \St_s$. This is a problem, since in our CSE engine all states are initialised as $\bot$ and can only be built upon via actions or predicate production, one predicate at a time (this problem wouldn't exist if we could produce a pair of predicates). It seems here that the consume-produce interface of our engine, which allows creating state bit by bit, can thus be unadapted for certain RAs. Of course one can define additional predicate for a specific product instantiation that combines predicates of underlying state models, however this go against the core idea of state model transformers to minimise the amount of effort needed to construct new state models. Finally, we also note that this problem is not encountered in $\Product_\PCM$, since there the unit of the PCM can be defined as $(0_1, 0_2)$ and work straightforwardly.

We define an alternative product RA that is more suited to this engine: \begin{align*}
	\Product(\mmdl_1,\mmdl_2) \defeq \mmdl_1 \times \mmdl_2 &\defeq (\St_1^? \times \St_2^?) \setminus \{(\bot, \bot)\}\\
	(\st_l, \st_r) \cdot (\st_l', \st_r') &\defeq (\st_l \cdot \st_l', \st_r \cdot \st_r')\\
	|(\st_l, \st_r)| &\defeq \begin{cases}
		\bot &\If~|\st_l|=\bot\land |\st_r|=\bot\\
		(|\st_l|, |\st_r|) &\Otherwise
 	\end{cases}
\end{align*}

We take advantage of the option state model $-^?$ and use that instead, thus allowing either sides of the product to be $\bot$. Crucially however, we exclude the $(\bot, \bot)$ state and ensure in the $\fn{wrap}$ helper that it never occurs (see \autoref{fig:product-rules-example}). This is important, because it means \emph{exclusivity} is carried: if for $(\st_l,\st_r)$ we have ${\isexowned~\st_l \land \isexowned~\st_r}$, then it also follows that $\isexowned~(\st_l, \st_r)$. If we hadn't excluded $(\bot, \bot)$, then it would always be the case that $(\st_l,\st_r)\cdot(\bot,\bot)$ holds, meaning that the state could never be exclusively owned. This is unpractical, as it would mean that disposing of a product is not frame preserving.

\begin{figure}
	\centering
\begin{align*}
	\text{Given }
	\mathit{wrap}(x, y) = \begin{cases}
		\bot &\If~x=\bot \land y=\bot\\
		(x,y) &\Otherwise
	 \end{cases} \text{ and }
	 \mathit{unwrap}(s) = \begin{cases}
 		(\bot, \bot) &\If ~s=\bot\\
		(x, y) &\Otherwise
	 \end{cases}
\end{align*}
	\begin{mathpar}
\inferrule[ProductLAction]{(\sst_l,\sst_r)=\mathit{unwrap}(\sst) \\ \ppexec{\alpha}{\sst_l,\sins}{o,\sst_l',\souts,\pc} \\ \sst' = \mathit{wrap}(\sst_l',\sst_r) \\ o \neq \Miss}{\ppexec{\code{L}\alpha}{\sst,\sins}{o,\sst',\souts,\pc}}
\end{mathpar}
	\caption{Example of action rules in \Product}
	\label{fig:product-rules-example}
\end{figure}

\subsection{Freeable}

The $\Freeable(\mmdl)$ state model transformer allows extending a state model with a \free{} action, that allows freeing a part of memory. The freed memory can then not be accessed, and attempting to use it raises a use-after-free error. This is similar to the \textsc{OneShot} RA of Iris, with the key difference that the \freedP{} predicate used to mark a resource as freed is \emph{not duplicable}. Iris defines $\textsc{OneShot}(X) \defeq \Ex(\{1\}) + \Ag(X)$ \cite{iris}, which is not UX-sound; in order for the switch of the side of a sum to be UX-sound, the resulting state (here, $\freed$) must be exclusively owned, which of course $\Ag$ never is. This is not a problem for Iris, that is only concerned with OX soundness, but because our goal is to make our state models both OX and UX sound for additional flexibility, we do make this change.

To ensure frame preservation, the underlying state model must provide an additional function ${\isexowned\colon\St\rarr\bools}$, which equates to the property `exclusive' presented before. Because actions in the symbolic realm need to be sound with regards to the concrete realm, we then lift its definition to ${\isexowned\colon\Sst\rarr\LVal}$, making it return a symbolic value, that can be appended to the path condition.

While not needed for the core and compositional engines, the bi-abductive engine requires that  misses may be fixed; $\Freeable(\mmdl)$ however cannot access directly the core predicates of \mmdl{} to provide fixes when freeing an empty state. As such, the state model must also provide a ${\code{fix\_owned}\colon\Sst^?\rarr\lvallist}$ function that returns possible fixes to make the given state exclusively owned. This also implies that for any state $\st$ of \mmdl{}, if it is not exclusively owned then there exists a bigger state $\st'$ such that $\st\preo\st' \land \isexowned~\st'$. This is not the case, for instance, for \Ag. As such, constructions such as $\Freeable(\Ag(X))$ are not sound.

Similarly to Iris, we define the $\Freeable(\mmdl)$ state model by construction: $\Freeable(\mmdl) \defeq \mmdl + \Ex(\{\freed\})$, which allows all associated rules to be kept. For clarity, we rename the core predicate $\code{R}~\exP$ (defined by~$\Ex(\{\freed\})$) as $\freedP$. We also extend its actions with the $\free$ action.

Because \Freeable{} is constructed via other state model transformers, we only need to describe the rules for \free{}, whcih are shown in  as seen in \autoref{fig:freeable-free-rules} -- the rest of the construction is already sound. This shows how simpler state models can be extended while alleviating the user from the burden of proving the soundness of the base construction.

\begin{figure}
	\centering
	\begin{mathpar}
\inferrule[FreeableActionFree]{}{\ppexec{\free}{l(\sst),[]}{\Ok,r(\ex\freed),[],[\isexowned~\sst]}}
\and\inferrule[FreeableActionFreeErr]{}{\ppexec{\free}{l(\sst),[]}{\Miss,l(\sst),\code{fix\_owned}~\sst,[\neg\isexowned~\sst]}}
\and\inferrule[FreeableActionFreeMiss]{}{\ppexec{\free}{\bot,[]}{\Miss,\bot,\code{fix\_owned}~\bot,[]}}
\and\inferrule[FreeableActionDoubleFree]{}{\ppexec{\free}{r(\ex\freed),[]}{\Err,r(\ex\freed),[],[]}}
\end{mathpar}
	\caption{Symbolic action rule of \Freeable}
	\label{fig:freeable-free-rules}
\end{figure}

Conveniently, use-after-free errors are already handled by the sum construction, thanks to the \textsc{SumLActionIncompat} rule which forbids actions from one side of the sum to be executed on the other side.

\subsection{Partial Map}

The partial map state model transformer $\PMap(I,\mmdl)$ is perhaps one of the most important state model transformers, as it allows having multiple state instances at different addresses and accessing them. It is constructed from a domain, $I\subseteq\Val$, and a state model for the codomain. For instance, the traditional separation logic heap can be modelled as $\PMap(\nats, \Ex(\Val))$. The C and the JavaScript memory models can also both be modelled using a $\PMap$, despite them being radically different. 

It defines one action, \alloc{}, and one core predicate, \domainset. It also \emph{lifts} all actions and predicates of the underlying model, adding to them an index argument or in-value. For instance, while for $\Ex(X)$ one has the core predicate $\corepred{\exP}{}{x}$, for $\PMap(\Ex(X))$ one would instead have predicate of the form $\corepred{\exP}{i}{x}$, which corresponds to the ``points to'' assertion $i\mapsto x$. We define it's RA as: \begin{breakalign*}
	\PMap(I,\mmdl) &\defeq (I \finmap \mmdl.\Sigma) \times \pset(I)^?\\
	(h,d)\cdot (h',d') &\defeq (h'', d'') \\
	\text{where } h''&\defeq \lambda i.\begin{cases}
		h(i)\cdot h'(i)&\If~i\in \dom(h)\cap\dom(h')\\
		h(i) &\If~i\in \dom(h) \setminus \dom(h')\\
		h'(i) &\If~i\in \dom(h') \setminus \dom(h)\\
		\text{undefined}&\Otherwise
	\end{cases}\\
	\text{and }d''&\defeq\begin{cases}
		d&\If~d'=\bot\\
		d'&\If~d=\bot\\
		\text{undefined}&\Otherwise
	\end{cases}\\
	\text{and }& d'' = \bot \lor \dom(h'')\subseteq d''\\
	|(h, d)| &\defeq \begin{cases}
		\bot &\If~\dom(h')=\emptyset\\
		(h', \bot) &\Otherwise
	\end{cases}\\
	\text{where }h'&\defeq \lambda i.\begin{cases}
		|h(i)| &\If~ i\in\dom(h) \land |h(i)| \neq \bot\\
		\text{undefined} &\Otherwise
	\end{cases}
\end{breakalign*}

An element of \PMap{} is of the form $(h, d)$, where $h$ are the mappings from locations to states, and $d$ is the \emph{domain set}, the set of indices that are known to exist. It is defined such that $\dom(h)\subseteq d$ always holds. The domain can also be $\bot$, in which case there is no knowledge on what addresses exist or don't. The aim of the domain set is to allow separating invalid accesses from misses: if $d\neq\bot$, then any access to $i\notin d$ leads to an $\Err$ outcome, however if $i\in d$ and the binding does not exist in the heap, then a $\Miss$ is raised.

As a consequence of this, $\PMap(I,\mmdl)$ has an additional requirement for $\mmdl$: any action execution on $\bot$ must lead to a $\Miss$. \begin{align*}
	\ppexec{\alpha}{\bot,\ins}{o,\st',\outs,\pc} \implies o=\Miss
\end{align*}

This is needed for frame preservation; if this wasn't the case, one could run into a case where the action of a cell in the heap succeeds on an empty heap, but an empty domain set would be compatible with the state, despite its composition with the state leading to a different outcome (an \Err).

This constraint also comes from the fact that \PMap{} can't automatically yield a \Miss{} when executing actions on missing cells, and must instead execute the action on $\bot$. Indeed, because $\PMap(I,\mmdl)$ can accept any underlying state model, it does not ``know'' what values are needed to fix the missing cell. Instead, it needs $\mmdl$ to raise a $\Miss$ that it can then lift with an index.

As mentioned before, \PMap{} lifts actions and core predicates, adding to them an index. Getting the state associated to an index is not simple, and will in fact be the target of several optimisations in \cref{sec:theory-optim-pmap}. For now we consider the simplest form of symbolic matching: either the index is present in the heap, or it isn't -- if it isn't and the domain set is not $\bot$, we also know that it must in the domain set. This creates three rules one must consider. For instance, given a state $([\sym a\mapsto \sym x, \sym b \mapsto \sym y], \bot)$, when an action is executed with index $\sym c$, three branches are created: either $\sym a = \sym c$, or $\sym b = \sym c$, or $\sym c$ is not part of the current heap, giving us $\sym c\notin \{\sym a,\sym b\}$.

Because most \execac, \consume{} and \produce{} rules of \PMap{} require retrieving states at a specific index, we introduce an abstraction over this, with the \code{get} and \code{set} functions. The former allows getting the state at an index \emph{with branching}; its signature is $\code{get}\colon \PMap(I,\mmdl)^? \rarr I \rarr \pset(I \times \St^? \times \Pc)$, as it returns the an index to modify exactly the returned state, the state itself, and a path condition corresponding to the branch. The $\code{set}$ function has signature $\code{set}\colon \PMap(I,\mmdl)^?\rarr I \rarr \St^? \rarr \PMap(I,\mmdl)^?$. Unlike for \code{get}, we don't allow branching when setting: because branching already happened when getting, and \code{get} returns the index to use to modify the state, we can use this new index and be guaranteed that it is sound. For instance for the above example, the three executions are ${\ppget{\sst,\sym c}{\sym a, \sst_a, [\sym c = \sym a]}}$, ${\ppget{\sst, \sym c}{\sym b, \sst_b, [\sym c = \sym b]}}$ and ${\ppget{\sst,\sym c}{\sym c, \bot, [\sym c\notin \{\sym a,\sym b\}]}}$. We present the rules for \code{get} in \autoref{fig:pmap-get-rules}.

\begin{figure}
	\centering
	\begin{mathpar}
\inferrule[PMapGetMatch]{(\sym h,\sym d)=\fn{unwrap}(\sst) \\ \sym i'\in\dom(\sym h) \\ \sst_i=\sym h(\sym i')}{\ppget{\sst, \sym i}{\sym i', \sst_i, [\sym i=\sym i']}}
\and\inferrule[PMapGetAdd]{(\sym h,\sym d)=\fn{unwrap}(\sst) \\ \sym i\notin\dom(\sym h) \\ \sym d\neq\bot}{\ppget{\sst, \sym i}{\sym i,\bot, [\sym i\notin\dom(\sym h) \land \sym i\in \sym d]}}
\and\inferrule[PMapGetBotDomain]{(\sym h,\sym d)=\fn{unwrap}(\sst) \\ \sym i\notin \dom(\sym h) \\ \sym d=\bot}{\ppget{\sst,\sym i}{\sym i,\bot,[\sym i\notin\dom(\sym h)]}}
\end{mathpar}
	\caption{Rules for \code{get} for \PMap}
	\label{fig:pmap-get-rules}
\end{figure}

Another unseemingly complex aspect of \PMap{} is allocation, for which the rules are presented in \autoref{fig:pmap-alloc-rules}. To allow instantiating, the wrapped state model must provide an \code{instantiate} function defined as $\code{instantiate}\colon \Val \rarr \St$, such that given the arguments given to $\alloc$, it returns a newly instantiated state. An initial definition of \PMap{} had \alloc{} always succeed; for instance, a $\bot$ state could alloc, resulting in $([\sym i\mapsto \st_i], \bot)$, with $\st_i$ the instantiated state. This however does not satisfy \ref{eq:frame-sub}: the frame $(\emptyset, \{\})$, made of an empty heap and the empty domain set, is compatible with the state before the allocation, but is not compatible with the state after, since the domain of the heap $\{\sym i\}$ is not a subset of $\{\}$. We must thus enforce ownership of the domain set when allocating. This is odd: in allocation-based languages like C, one can always allocate a new cell, without needing to ``own'' anything, as the allocator is global. With this definition of \alloc{} however, one can't allocate without it, which can be problematic: for instance in a multi-threaded setting, two threads cannot own the domain set, since it is exclusively owned to allow modification.

This is a weakness of this \PMap{} definition, as we require a more restrictive behaviour than what is usually admitted with allocation. This also has the unfortunate side effect that whenever a function needs to allocate, it must specify a \domainset{} core predicate in its pre and postcondition, which can become quite verbose and unpractical. Attempts have been made to preserve the domain set while allowing for more flexible allocation semantics, for instance by having the domain set be a duplicable resource that allows modification, by defining composition as set union. However these relaxations often had as a consequence that out of bounds accesses couldn't reliably be detected anymore, as indeed more heap cells with a larger domain set could always be composed to yield a succesful outcome. In fact allocation seems to be a topic that is in essence hard to tackle with separation logic; \cite{seplogic2,localreasoning} already mentioned some of these difficulties regarding freshness of the new index.

\begin{figure}
	\centering
	\begin{mathpar}
\inferrule[PMapAlloc]{\sym d\neq \bot \\ \sym i = \code{fresh}~I \\ \sst_i=\code{instantiate}(\sins) \\ \sym h' = \sym h[\sym i\leftarrow \sst_i] \\ \sym d' = \sym d\uplus \{\sym i\}}{\ppexec{\alloc}{(\sym h,\sym d), \sins}{\Ok, (\sym h',\sym d'), [\sym i], [\sym i=\sym i]}}
\and\inferrule[PMapAllocMiss]{(\sym h,\sym d)=\fn{unwrap}(\sst) \\ \sym d=\bot}{\ppexec{\alloc}{\sst,\sins}{\Miss,\sst,[\strv{domainset}],[]}}
\end{mathpar}
	\caption{Rules for \alloc{} for \PMap}
	\label{fig:pmap-alloc-rules}
\end{figure}

A solution to the above problem is to simply get rid of the domain set, and define \PMap{} only as the mappings from indices to states. This works, however one loses the ability to detect out of bounds accesses entirely, as additional cells can always be composed with the state to yield a non-\Miss{} outcome. For our purposes however, we keep the definition using a domain set, as it is more powerful.

\subsection{Partial Map Variations}

The behaviour of \PMap{} is not always adapted for the state one wants to model. Here we describe in a shorter form some state models that function similarly to \PMap.

\subsubsection{Dynamic Partial Map}

The \emph{dynamic} partial map, $\DynPMap(I,\mmdl)$, allows dynamically allocating missing cells when they're accessed. It is used, for instance, when modelling objects in JavaScript. In JavaScript, accessing a property that hasn't been set simply yields a default value, \code{undefined}, and any property of an object can be set directly without needing to allocate it first. This can be easily achieved by modifying \PMap, such that any out of bounds accesses have the effect of instantiating the state at that location, storing it, and executing the action against it. In other words, instead of using the domain set to distinguish between \Err{} and \Miss, we use it to distinguish between \Ok{} and \Miss \cite{sacha-phd}.

We also need to remove the \alloc{} action, since allocation has no reason to exist; the cell can be modified directly instead.

\subsubsection{List}

The list state model, $\List(\mmdl)$, allows storing a list of states up to a bound. Instead of having a domain set, we define it as having a bound $n$ such that all indices $i$ are in $[0;n($. It is useful when wanting to represent continuous blocks of memory of known size. We use it for the state model of WISL, which uses a simple block-offset memory model: each memory access requires an address of the block, and the offset within the block to read from.

Because the bound can also be $\bot$, it serves the exact same purpose as the domain set in \PMap{}: distinguishing out of bounds from misses.

\subsubsection{General Map}

Due to the strong similarity between $\PMap$ and $\List$, it is tempting to define a more general sort of map state model, that allows replicating both behaviours. The general map $\GMap$ allows this; constructed as $\GMap(I,\mmdl,\mmdl_D)$, it receives the same domain set and codomain state model as before, but it also receives a \emph{discriminator} state model $\mmdl_D$, which represents the state which is capable of discriminating out of bounds accesses from missing accesses.

The discriminator must come equipped with a $\code{is\_within}\colon \St_D \rarr I \rarr \bools$ function that given an index returns whether or not the state is within bounds. Here, the input discriminator state is never $\bot$: if the discriminator is not known then a \Miss{} must be issued, since composing a state with a non-$\bot$ discriminator can change the outcome. \code{is\_within} must also be lifted to the symbolic realm, resulting in $\code{is\_within}\colon \Sst_D\rarr I\rarr \pset(\LVal)$. 

Defining \PMap{} and \List{} with a \GMap{} would require using the discriminator state models $\Ex(\pset(I))$ and $\Ex(\nats)$ respectively, with the following $\code{is\_within}$ definitions: \begin{align*}
	\code{is\_within}_{\PMap}~d~i&\defeq i\in d\\
	\code{is\_within}_{\List}~n~i&\defeq 0 \leq i \land i < n
\end{align*}

For the above two examples it is also needed to exclude the $\store$ actions defined by the discriminator (via \Ex), as modifying the domain set of a partial map or the bound of a list is not frame preserving. In general, it is unsound to modify the discriminator directly without also modifying the map: ``increasing'' it breaks \ref{eq:frame-add} (as states compatible with the new state aren't compatible with the old state), while ``decreasing'' it breaks \ref{eq:frame-sub} (for the inverse reason). Here increasing and decreasing refer to modifying the discriminator such that more or less indices are considered \emph{within} it.




\subsection{Syntactic Checking}

\subsection{Split PMap}

\subsection{Abstract Location PMap}





